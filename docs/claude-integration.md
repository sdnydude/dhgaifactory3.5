# Claude AI Integration Guide

This guide explains how to import your Claude AI conversations, projects, and artifacts into the DHG Registry for centralized knowledge management.

## Overview

The DHG Registry can store:
- **Conversations**: Complete chat histories with Claude
- **Projects**: Claude Projects with custom instructions and knowledge files
- **Artifacts**: Code, documents, and visualizations generated by Claude
- **Messages**: Individual user and assistant messages with full context

## Data Export from Claude

### Method 1: Official Export (Recommended)

1. Go to Claude settings (click your initials in lower-left)
2. Select **Settings** → **Privacy**
3. Click **Export Data**
4. You'll receive an email with a download link (valid for 24 hours)
5. Download the ZIP file

**Includes**: All conversations, projects, complete history

### Method 2: Browser Extension (Per-Conversation)

Use browser extensions for recent conversations or specific exports:
- **Claude Exporter** (Chrome): Exports to Markdown, JSON, PDF
- **Claude Chat Downloader** (Userscript): TXT, MD, CSV, JSON

**Best for**: Recent conversations, selective exports

## Importing Data

### Prerequisites

Ensure the stack is running:
```bash
cd /home/swebber64/DHG/aifactory3.5/dhgaifactory3.5
make up
```

### Run Database Migration

First time only - create the Claude tables:
```bash
cd registry
docker exec -it dhg-registry-api alembic upgrade head
```

### Import Official Export

```bash
cd registry
python3 ingest_claude_data.py \
  --source official_export \
  --input ~/Downloads/claude_export.zip
```

**Options**:
- `--dry-run` - Validate without importing
- `--merge` - Update existing conversations instead of skipping

### Import Markdown Files

Single file:
```bash
python3 ingest_claude_data.py \
  --source markdown \
  --input ~/claude_exports/conversation.md
```

Directory of files:
```bash
python3 ingest_claude_data.py \
  --source markdown_dir \
  --input ~/claude_exports/
```

## Querying Data

### REST API

Once imported, query via the Registry API at http://localhost:8000:

**List conversations**:
```bash
curl http://localhost:8000/api/v1/conversations
```

**Search conversations**:
```bash
curl "http://localhost:8000/api/v1/conversations/search?q=python"
```

**Get conversation messages**:
```bash
curl http://localhost:8000/api/v1/messages/conversation/{conversation_id}
```

**List artifacts**:
```bash
curl http://localhost:8000/api/v1/artifacts
```

**Filter by artifact type**:
```bash
curl "http://localhost:8000/api/v1/artifacts?artifact_type=code"
```

**List projects**:
```bash
curl http://localhost:8000/api/v1/projects
```

### Database Queries

Connect directly to PostgreSQL:
```bash
docker exec -it dhg-registry-db psql -U dhg_user -d dhg_registry
```

Example queries:
```sql
-- Count conversations by export source
SELECT export_source, COUNT(*) 
FROM conversations 
GROUP BY export_source;

-- Find conversations with most messages
SELECT c.title, COUNT(m.id) as message_count
FROM conversations c
JOIN messages m ON m.conversation_id = c.id
GROUP BY c.id, c.title
ORDER BY message_count DESC
LIMIT 10;

-- List Python code artifacts
SELECT title, language, created_at
FROM artifacts
WHERE language = 'python'
ORDER BY created_at DESC;

-- Search message content
SELECT c.title, m.role, LEFT(m.content, 100) as preview
FROM messages m
JOIN conversations c ON c.id = m.conversation_id
WHERE m.content ILIKE '%machine learning%'
LIMIT 20;
```

## Data Schema

### Tables

- **projects**: Claude Projects with custom instructions
- **conversations**: Chat threads with metadata
- **messages**: Individual messages (user/assistant)
- **artifacts**: Code and documents generated by Claude

### Relationships

```
projects (1) ─────→ (many) conversations
conversations (1) ──→ (many) messages
conversations (1) ──→ (many) artifacts
messages (1) ────────→ (many) artifacts [optional]
```

## Ongoing Sync

### Manual Periodic Exports

Schedule regular exports to keep data current:

1. Request Claude export monthly/quarterly
2. Download ZIP file
3. Run ingestion with `--merge` flag:
   ```bash
   python3 ingest_claude_data.py \
     --source official_export \
     --input claude_export_2025-12.zip \
     --merge
   ```

### Browser Extension Workflow

For daily/weekly updates of recent conversations:

1. Export individual conversations using browser extension
2. Save to a watched directory
3. Run batch import:
   ```bash
   python3 ingest_claude_data.py \
     --source markdown_dir \
     --input ~/claude_exports/ \
     --merge
   ```

## Troubleshooting

### Migration Fails

Check if migration already ran:
```bash
docker exec -it dhg-registry-api alembic current
```

If stuck, check database:
```bash
docker exec -it dhg-registry-db psql -U dhg_user -d dhg_registry -c "\dt"
```

### Import Errors

Run with dry-run to validate:
```bash
python3 ingest_claude_data.py --dry-run --source official_export --input export.zip
```

Check logs:
```bash
docker logs dhg-registry-api
```

### Duplicate Conversations

By default, existing conversations are skipped. Use `--merge` to update:
```bash
python3 ingest_claude_data.py --merge --source official_export --input export.zip
```

## API Documentation

Full API documentation available at:
http://localhost:8000/docs

Includes:
- Interactive API testing
- Request/response schemas
- Authentication (if configured)

## Next Steps

- **Grafana Dashboards**: Visualize conversation metrics
- **Full-Text Search**: Implement PostgreSQL full-text search on message content
- **Vector Embeddings**: Add pgvector for semantic search
- **Automated Sync**: Build file watcher for auto-import
